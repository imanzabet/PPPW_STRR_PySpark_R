{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print (os.environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import random\n",
    "\n",
    "sc = pyspark.SparkContext(appName=\"Pi\")\n",
    "\n",
    "num_samples = 100000000\n",
    "\n",
    "def inside(p):     \n",
    "  x, y = random.random(), random.random()\n",
    "  return x*x + y*y < 1\n",
    "\n",
    "count = sc.parallelize(range(0, num_samples)).filter(inside).count()\n",
    "\n",
    "pi = 4 * count / num_samples\n",
    "print(pi)\n",
    "\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "sc= SparkContext()\n",
    "sqlContext = SQLContext(sc)\n",
    "house_df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('boston.csv')\n",
    "house_df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "for i in house_df.columns:\n",
    "    if not( isinstance(house_df.select(i).take(1)[0][0], six.string_types)):\n",
    "        print( \"Correlation to MV for \", i, house_df.stat.corr('MV',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler = VectorAssembler(inputCols = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PT', 'B', 'LSTAT'], outputCol = 'features')\n",
    "vhouse_df = vectorAssembler.transform(house_df)\n",
    "vhouse_df = vhouse_df.select(['features', 'MV'])\n",
    "vhouse_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = vhouse_df.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='MV', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(train_df)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cox model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Covariate pdiab has missing values.\n",
      "WARNING: Covariate pdismiss has missing values.\n",
      "WARNING: Covariate pnhprev has missing values.\n",
      "WARNING: Covariate bmi_msg has missing values.\n",
      "WARNING: Covariate ashd1 has missing values.\n",
      "WARNING: Covariate othcardiac1 has missing values.\n",
      "WARNING: Covariate carfail has missing values.\n",
      "WARNING: Covariate noambul has missing values.\n",
      "WARNING: Covariate pulmon has missing values.\n",
      "WARNING: Covariate notrans has missing values.\n",
      "WARNING: Covariate cancer has missing values.\n",
      "WARNING: Covariate diabetes has missing values.\n",
      "WARNING: Covariate pvasc has missing values.\n",
      "WARNING: Covariate cva has missing values.\n",
      "WARNING: Covariate smoke has missing values.\n",
      "WARNING: Covariate alcoh has missing values.\n",
      "WARNING: Covariate drug has missing values.\n",
      "WARNING: Covariate inci_one has missing values.\n",
      "WARNING: Covariate inci_miss has missing values.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>2 hours 23 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.30.1.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>2 months and 4 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_root_z8cwc4</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>25.25 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>32</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>32</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.7.9 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         2 hours 23 mins\n",
       "H2O_cluster_timezone:       UTC\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.30.1.3\n",
       "H2O_cluster_version_age:    2 months and 4 days\n",
       "H2O_cluster_name:           H2O_from_python_root_z8cwc4\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    25.25 Gb\n",
       "H2O_cluster_total_cores:    32\n",
       "H2O_cluster_allowed_cores:  32\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.7.9 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import s3fs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_columns = None\n",
    "# csv file\n",
    "df_all = pd.read_csv(\"s3://eqrs-ngmc-datascience/Datascience/x.csv\")\n",
    "df = df_all#[:50000]\n",
    "\n",
    "# as.Date(data$strr_pyf_start, format=\"%m/%d/%Y\")\n",
    "df['strr_pyf_start'] = pd.to_datetime(df['strr_pyf_start']).dt.strftime('%m/%d/%Y')\n",
    "# df['provfs'] = df['provfs'].astype(str)\n",
    "df['provfs'] = pd.to_numeric(df['provfs'], downcast='integer', errors='coerce').fillna(0)\n",
    "df['provfs'] = df['provfs'].astype(int)\n",
    "col_names = df.columns\n",
    "\n",
    "# sorting with three columns\n",
    "z_pd = df.to_records()\n",
    "z_pd.sort(order=[\"provfs\", \"ptnt_id\", \"year\"])\n",
    "d2 = pd.DataFrame(z_pd)\n",
    "\n",
    "classnames = (\n",
    "\"pdiab\", \"pdismiss\", \"pnhprev\", \"bmi_msg\", \"ashd1\", \"othcardiac1\",\n",
    "\"carfail\", \"noambul\", \"pulmon\", \"notrans\", \"cancer\", \"diabetes\",\n",
    "\"pvasc\", \"cva\", \"smoke\", \"alcoh\", \"drug\", \"inci_one\", \"inci_miss\"\n",
    ")\n",
    "\n",
    "#R     z <- match(classnames, names(data2))\n",
    "z = [ list(d2.columns).index(x) if x in d2.columns else None for x in  classnames]\n",
    "\n",
    "for i in range(0, len(z)):\n",
    "    col_mean = float(d2.iloc[:, [z[i]]].mean())\n",
    "    if(col_mean<0.001 or col_mean>0.999):\n",
    "        print(\"WARNING: Covariate\", classnames[i],\"has less than 0.1% variation.  The distribution of this covariate is\", col_mean)\n",
    "    else:\n",
    "        print(\"WARNING: Covariate\", classnames[i], \"has missing values.\")\n",
    "\n",
    "\n",
    "\n",
    "cols = [\"ptnt_id\", \"provfs\", \"t_trans\", \"strr_pyf_start\", \"wt_trans\", \"ot_trans\",\"pdiab\", \n",
    "        \"pdismiss\", \"pnhprev\",  \"logbmi\", \"bmi_msg\", \"agecat6\", \"year\", \"pyf_period_esrd\",  \n",
    "        \"t_start\", \"t_stop\", \"ashd1\", \"othcardiac1\", \"carfail\", \"noambul\",  \"pulmon\", \n",
    "        \"notrans\", \"cancer\", \"diabetes\", \"pvasc\", \"cva\",  \"smoke\", \"alcoh\", \"drug\", \"inci_one\", \"inci_miss\"]\n",
    "z2 = d2[cols]\n",
    "\n",
    "missing_z2 = z2.isna()\n",
    "\n",
    "if sum(missing_z2.sum(axis=0))>0:\n",
    "  print(\"Warning: There are\", sum(missing_z2.sum(axis=0)), \"rows with missing data\")\n",
    "  print(\"Any rows with missing data will be deleted\")\n",
    "\n",
    "allnames= [\"ptnt_id\",\"provfs\",\"t_trans\", \"strr_pyf_start\",\"wt_trans\",\"ot_trans\",\"pdiab\",\"pdismiss\",\n",
    "    \"pnhprev\",\"logbmi\",\"bmi_msg\",\"agecat6\",\"year\",\"pyf_period_esrd\",\"t_start\",\"t_stop\",\"ashd1\", \n",
    "    \"othcardiac1\", \"carfail\",\"noambul\", \"pulmon\", \"notrans\", \"cancer\", \"diabetes\",\n",
    "    \"pvasc\", \"cva\", \"smoke\",\"alcoh\", \"drug\",\"inci_one\",\"inci_miss\",\n",
    "    \"strr_period\", \"pstrr\", \"trans_yar\", \"trans_dar\"]\n",
    "\n",
    "\n",
    "data_sub = d2[allnames]\n",
    "data_sub_complete=data_sub\n",
    "\n",
    "########################################################################################\n",
    "#  SECTION 7 (ISSUE #3): CREATE TRANSFUSION EVENT FLAG                                 #\n",
    "#    -CHECK FOR SMALL NUMBER OF EVENTS                                                 #                                           \n",
    "########################################################################################\n",
    "data_sub_complete['t_trans0'] = np.where(data_sub_complete['t_trans']>0, 1, 0)\n",
    "data_sub_complete['t_trans']=data_sub_complete['t_trans'].apply(lambda x: 1 if x > 0 else 0).copy()\n",
    "# data_sub_complete.loc[data_sub_complete.t_trans > 1, 't_trans'] = 1\n",
    "# data_sub_complete.loc[data_sub_complete.t_trans <= 0, 't_trans'] = 0\n",
    "\n",
    "########################################################################################\n",
    "#   SECTION 8: SUBSET DATA TO THOSE WITH AT LEAST 1 DAY AT RISK                        #\n",
    "#     -ALSO SUBSET TO THOSE WITH APPROPRIATE AGE AND ESRD CATEGORIES                   #\n",
    "#   NOTE: THIS IS MOSTLY DONE JUST TO BE PRECAUTIOUS FOR TEST DATA                     #\n",
    "########################################################################################\n",
    "data_sub_complete2 = data_sub_complete[(data_sub_complete['pyf_period_esrd']>0) & (data_sub_complete['agecat6']!=1) & (data_sub_complete['trans_dar']>0)]\n",
    "\n",
    "########################################################################################\n",
    "#   SECTION 9 (ISSUE #5): CHECK FOR LINEARLY DEPENDENT COVARIATES                      #\n",
    "#      NOTE: THIS WON'T PREVENT MODEL FROM RUNNING                                     #\n",
    "########################################################################################\n",
    "\n",
    "z_pd = data_sub_complete2.to_records()\n",
    "z_pd.sort(order=[\"provfs\", \"ptnt_id\", \"year\", \"strr_pyf_start\"])\n",
    "data_sub_sort = pd.DataFrame(z_pd)\n",
    "data_chk_rank = data_sub_sort.drop([\"strr_pyf_start\",\"provfs\",\"ptnt_id\"], axis = 1) \n",
    "\n",
    "########################################################################################\n",
    "#   SECTION 10: RUN DATA THROUGH TWO COX PROPORTIONAL HAZARDS MODELS                   #\n",
    "########################################################################################\n",
    "data_sub_sort['year'] = pd.Categorical(data_sub_sort['year'], ordered=False)\n",
    "data_sub_sort['pdismiss'] = pd.Categorical(data_sub_sort['pdismiss'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['pnhprev'] = pd.Categorical(data_sub_sort['pnhprev'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['bmi_msg'] = pd.Categorical(data_sub_sort['bmi_msg'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['ashd1'] = pd.Categorical(data_sub_sort['ashd1'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['othcardiac1'] = pd.Categorical(data_sub_sort['othcardiac1'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['carfail'] = pd.Categorical(data_sub_sort['carfail'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['noambul'] = pd.Categorical(data_sub_sort['noambul'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['pulmon'] = pd.Categorical(data_sub_sort['pulmon'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['notrans'] = pd.Categorical(data_sub_sort['notrans'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['cancer'] = pd.Categorical(data_sub_sort['cancer'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['diabetes'] = pd.Categorical(data_sub_sort['diabetes'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['pvasc'] = pd.Categorical(data_sub_sort['pvasc'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['cva'] = pd.Categorical(data_sub_sort['cva'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['smoke'] = pd.Categorical(data_sub_sort['smoke'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['alcoh'] = pd.Categorical(data_sub_sort['alcoh'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['drug'] = pd.Categorical(data_sub_sort['drug'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['inci_one'] = pd.Categorical(data_sub_sort['inci_one'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['inci_miss'] = pd.Categorical(data_sub_sort['inci_miss'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['smoke'] = pd.Categorical(data_sub_sort['smoke'], categories=[0, 1], ordered=False)\n",
    "\n",
    "data_sub_sort['provfs'] = pd.Categorical(data_sub_sort['provfs'], ordered=False)\n",
    "\n",
    "# coxph_control <- coxph.control(eps = 1e-8)\n",
    "# data_sub_sort.transform(lambda x: x + 1)\n",
    "\n",
    "data_model = data_sub_sort\n",
    "\n",
    "#######################################################################################################################################################\n",
    "# Run Stage-1 Cox Model\n",
    "######################################################################################################################################################\n",
    "import h2o\n",
    "from h2o.estimators.coxph import H2OCoxProportionalHazardsEstimator\n",
    "h2o.init()\n",
    "\n",
    "data_modelt_Full_Sample=data_model\n",
    "data_modelt_Full_Sample.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data_modelt_Full_Sample_hex = h2o.H2OFrame(data_modelt_Full_Sample)\n",
    "data_modelt_Full_Sample_hex[data_modelt_Full_Sample_hex[\"provfs\"].isna(), \"provfs\"] = 0\n",
    "# data_modelt_Full_Sample_hex[\"provfs\"] = data_modelt_Full_Sample_hex[\"provfs\"].ascharacter()\n",
    "# data_modelt_Full_Sample_hex[\"provfs\"] = data_modelt_Full_Sample_hex[\"provfs\"].asfactor()\n",
    "predictorsSt = list([\"agecat6\", \"pdiab\", \"pdismiss\",\"notrans\",\"cancer\",\n",
    "                \"diabetes\",\"pvasc\",\"year\", \"pnhprev\", \"logbmi\", \n",
    "                \"bmi_msg\",\"cva\",\"smoke\",\"alcoh\",\"drug\",\n",
    "                \"inci_one\", \"ashd1\", \"pulmon\",\"inci_miss\",\"year\",\n",
    "                \"othcardiac1\", \"carfail\", \"noambul\", \"pulmon\"])\n",
    "\n",
    "interaction_pairs = [   (\"agecat6\",\"pdiab\"), \n",
    "                        (\"pdiab\", \"pyf_period_esrd\")]\n",
    "\n",
    "strr_h2o_moodel = H2OCoxProportionalHazardsEstimator(\n",
    "    start_column=\"t_start\",\n",
    "    stop_column=\"t_stop\",\n",
    "    offset_column=\"ot_trans\",\n",
    "    ties=\"breslow\",\n",
    "#     stratify_by=[\"provfs\"],\n",
    "#     interaction_pairs=interaction_pairs,\n",
    "    )\n",
    "\n",
    "strr_h2o_moodel.train(x=predictorsSt,\n",
    "                y=\"t_trans0\",\n",
    "                training_frame=data_modelt_Full_Sample_hex)\n",
    "\n",
    "\n",
    "\n",
    "###########################\n",
    "# writing to csv\n",
    "# pd.DataFrame(data_modelt_Full_Sample_hex[\"provfs\"]).to_csv('provfs.csv')\n",
    "\n",
    "data_modelt_Full_Sample_hex['provfs'].types\n",
    "\n",
    "strr_h2o_moodel.coefficients_table\n",
    "data_modelt_Full_Sample_hex['t_trans0'].types\n",
    "data_modelt_Full_Sample_hex[\"t_trans0\"]\n",
    "len(data_modelt_Full_Sample_hex.col_names)\n",
    "data_modelt_Full_Sample_hex.types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3 CSV file read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_columns = None\n",
    "# csv file\n",
    "df_all = pd.read_csv(\"s3://eqrs-ngmc-datascience/Datascience/x.csv\")\n",
    "\n",
    "# parquet file\n",
    "# df = pd.read_parquet('s3://{bucket_name}/{path_to_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_all#[:50000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as.Date(data$strr_pyf_start, format=\"%m/%d/%Y\")\n",
    "df['strr_pyf_start'] = pd.to_datetime(df['strr_pyf_start']).dt.strftime('%m/%d/%Y')\n",
    "# df['provfs'] = df['provfs'].astype(str)\n",
    "df['provfs'] = pd.to_numeric(df['provfs'], downcast='integer', errors='coerce').fillna(0)\n",
    "df['provfs'] = df['provfs'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = df.columns\n",
    "df[\"provfs\"].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting with three columns\n",
    "z_pd = df.to_records()\n",
    "z_pd.sort(order=[\"provfs\", \"ptnt_id\", \"year\"])\n",
    "d2 = pd.DataFrame(z_pd)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = np.array(df[\"provfs\"].astype(int)).argsort()\n",
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  classnames = (\n",
    "    \"pdiab\", \"pdismiss\", \"pnhprev\", \"bmi_msg\", \"ashd1\", \"othcardiac1\",\n",
    "    \"carfail\", \"noambul\", \"pulmon\", \"notrans\", \"cancer\", \"diabetes\",\n",
    "    \"pvasc\", \"cva\", \"smoke\", \"alcoh\", \"drug\", \"inci_one\", \"inci_miss\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R     z <- match(classnames, names(data2))\n",
    "z = [ list(d2.columns).index(x) if x in d2.columns else None for x in  classnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#R\n",
    "#  for (i in 1:length(z)){\n",
    "#     if(is.na(mean(data2[,z[i]]))==FALSE){\n",
    "#       if(mean(data2[,z[i]])<0.001 || mean(data2[,z[i]])>0.999 ){\n",
    "#         print(paste(\"WARNING: Covariate\",toupper(classnames[i]),\"has less than 0.1% variation.  The distribution of this covariate is\", mean(data2[,z[i]])))\n",
    "#       }\n",
    "#     }else\n",
    "#     {\n",
    "#       print(paste(\"WARNING: Covariate\", toupper(classnames[i]), \"has missing values.\"))\n",
    "#     }\n",
    "#   }\n",
    "\n",
    "for i in range(0, len(z)):\n",
    "    col_mean = float(d2.iloc[:, [z[i]]].mean())\n",
    "    if(col_mean<0.001 or col_mean>0.999):\n",
    "        print(\"WARNING: Covariate\", classnames[i],\"has less than 0.1% variation.  The distribution of this covariate is\", col_mean)\n",
    "    else:\n",
    "        print(\"WARNING: Covariate\", classnames[i], \"has missing values.\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "###   adjustment variables\n",
    "# R  z2<-cbind(data2$ptnt_id, data2$provfs, data2$t_trans, data2$strr_pyf_start,\n",
    "#           data2$wt_trans, data2$ot_trans,data2$pdiab, data2$pdismiss, data2$pnhprev, \n",
    "#           data2$logbmi, data2$bmi_msg, data2$agecat6, data2$year, data2$pyf_period_esrd, \n",
    "#           data2$t_start, data2$t_stop, data2$ashd1, data2$othcardiac1, data2$carfail, data2$noambul, \n",
    "#           data2$pulmon, data2$notrans, data2$cancer, data2$diabetes, data2$pvasc, data2$cva, \n",
    "#           data2$smoke, data2$alcoh, data2$drug, data2$inci_one, data2$inci_miss)\n",
    "cols = [\"ptnt_id\", \"provfs\", \"t_trans\", \"strr_pyf_start\", \"wt_trans\", \"ot_trans\",\"pdiab\", \n",
    "        \"pdismiss\", \"pnhprev\",  \"logbmi\", \"bmi_msg\", \"agecat6\", \"year\", \"pyf_period_esrd\",  \n",
    "        \"t_start\", \"t_stop\", \"ashd1\", \"othcardiac1\", \"carfail\", \"noambul\",  \"pulmon\", \n",
    "        \"notrans\", \"cancer\", \"diabetes\", \"pvasc\", \"cva\",  \"smoke\", \"alcoh\", \"drug\", \"inci_one\", \"inci_miss\"]\n",
    "z2 = d2[cols]\n",
    "z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_z2 = z2.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# R\n",
    "# if(sum(rowSums(missing_z2)>0)){\n",
    "#   print(paste(\"Warning: There are\", sum(rowSums(missing_z2)>0), \"rows with missing data\"))\n",
    "#   print(paste(\"Any rows with missing data will be deleted\"))\n",
    "# }\n",
    "if sum(missing_z2.sum(axis=0))>0:\n",
    "  print(\"Warning: There are\", sum(missing_z2.sum(axis=0)), \"rows with missing data\")\n",
    "  print(\"Any rows with missing data will be deleted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# allnames=\n",
    "#   c(\"ptnt_id\",\"provfs\",\"t_trans\", \"strr_pyf_start\",\"wt_trans\",\"ot_trans\",\"pdiab\",\"pdismiss\",\n",
    "#     \"pnhprev\",\"logbmi\",\"bmi_msg\",\"agecat6\",\"year\",\"pyf_period_esrd\",\"t_start\",\"t_stop\",\"ashd1\", \n",
    "#     \"othcardiac1\", \"carfail\",\"noambul\", \"pulmon\", \"notrans\", \"cancer\", \"diabetes\",\n",
    "#     \"pvasc\", \"cva\", \"smoke\",\"alcoh\", \"drug\",\"inci_one\",\"inci_miss\",\n",
    "#     \"strr_period\", \"pstrr\", \"trans_yar\", \"trans_dar\")\n",
    "\n",
    "# data_sub <- data2[ ,allnames]\n",
    "# data_sub_complete<-data_sub                          #CHANGED CODE LINE HERE\n",
    "\n",
    "allnames= [\"ptnt_id\",\"provfs\",\"t_trans\", \"strr_pyf_start\",\"wt_trans\",\"ot_trans\",\"pdiab\",\"pdismiss\",\n",
    "    \"pnhprev\",\"logbmi\",\"bmi_msg\",\"agecat6\",\"year\",\"pyf_period_esrd\",\"t_start\",\"t_stop\",\"ashd1\", \n",
    "    \"othcardiac1\", \"carfail\",\"noambul\", \"pulmon\", \"notrans\", \"cancer\", \"diabetes\",\n",
    "    \"pvasc\", \"cva\", \"smoke\",\"alcoh\", \"drug\",\"inci_one\",\"inci_miss\",\n",
    "    \"strr_period\", \"pstrr\", \"trans_yar\", \"trans_dar\"]\n",
    "\n",
    "\n",
    "data_sub = d2[allnames]\n",
    "data_sub_complete=data_sub\n",
    "data_sub_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "#  SECTION 7 (ISSUE #3): CREATE TRANSFUSION EVENT FLAG                                 #\n",
    "#    -CHECK FOR SMALL NUMBER OF EVENTS                                                 #                                           \n",
    "########################################################################################\n",
    "#create flag for transfusions==>will be used in model as event\n",
    "# data_sub_complete$t_trans0 <- ifelse(data_sub_complete$t_trans>0, 1, 0)\n",
    "\n",
    "data_sub_complete['t_trans0'] = np.where(data_sub_complete['t_trans']>0, 1, 0)\n",
    "data_sub_complete['t_trans']=data_sub_complete['t_trans'].apply(lambda x: 1 if x > 0 else 0).copy()\n",
    "# data_sub_complete.loc[data_sub_complete.t_trans > 1, 't_trans'] = 1\n",
    "# data_sub_complete.loc[data_sub_complete.t_trans <= 0, 't_trans'] = 0\n",
    "data_sub_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data_sub_complete['provfs']==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "#   SECTION 8: SUBSET DATA TO THOSE WITH AT LEAST 1 DAY AT RISK                        #\n",
    "#     -ALSO SUBSET TO THOSE WITH APPROPRIATE AGE AND ESRD CATEGORIES                   #\n",
    "#   NOTE: THIS IS MOSTLY DONE JUST TO BE PRECAUTIOUS FOR TEST DATA                     #\n",
    "########################################################################################\n",
    "#subset to values that should not be in data, and to those with at least 1 day at risk\n",
    "\n",
    "#   data_sub_complete2 <- data_sub_complete[ which(data_sub_complete$pyf_period_esrd>0 &\n",
    "#                                                    data_sub_complete$agecat6 != 1 & data_sub_complete$trans_dar>0), ]\n",
    "  \n",
    "#   if(TO_LOG==1){\n",
    "#     cat(\"Step 1 of 4 completed - data cleaned up\", file=log_prog_strr, sep=\"\\n\")\n",
    "#     cat(\"Step 1 of 4 completed - data cleaned up\")\n",
    "#   }\n",
    "#   if(TO_LOG!=1){\n",
    "#     cat(\"Step 1 of 4 completed - data cleaned up\")\n",
    "#   }\n",
    "\n",
    "# data_sub_sort=data_sub_complete2[order(data_sub_complete2$provfs,data_sub_complete2$ptnt_id,\n",
    "#                                        factor(data_sub_complete2$year),data_sub_complete2$strr_pyf_start),] \n",
    "\n",
    "data_sub_complete2 = data_sub_complete[(data_sub_complete['pyf_period_esrd']>0) & (data_sub_complete['agecat6']!=1) & (data_sub_complete['trans_dar']>0)]\n",
    "data_sub_complete2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "#   SECTION 9 (ISSUE #5): CHECK FOR LINEARLY DEPENDENT COVARIATES                      #\n",
    "#      NOTE: THIS WON'T PREVENT MODEL FROM RUNNING                                     #\n",
    "########################################################################################\n",
    "# data_chk_rank <- data_sub_sort[ ,-which(names(data_sub_sort) %in% c(\"strr_pyf_start\",\"provfs\",\"ptnt_id\"))]\n",
    "\n",
    "# if(qr(data_chk_rank)$rank!=ncol(data_chk_rank)){\n",
    "#   print(paste(\"There is rank deficiency in covariates.\"))\n",
    "#   print(paste(\"Any collinear covariates are skipped over.\"))\n",
    "#   print(paste(\"This results in value of 'NA' for estimated coefficient. \"))\n",
    "# }\n",
    "z_pd = data_sub_complete2.to_records()\n",
    "z_pd.sort(order=[\"provfs\", \"ptnt_id\", \"year\", \"strr_pyf_start\"])\n",
    "data_sub_sort = pd.DataFrame(z_pd)\n",
    "data_chk_rank = data_sub_sort.drop([\"strr_pyf_start\",\"provfs\",\"ptnt_id\"], axis = 1) \n",
    "data_chk_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "#   SECTION 10: RUN DATA THROUGH TWO COX PROPORTIONAL HAZARDS MODELS                   #\n",
    "########################################################################################\n",
    "\n",
    "# #TRANSFORM CLASS VARIABLES INTO FACTORS, SO THAT R TREATS THESE APPROPRIATELY\n",
    "# data_model <- transform(data_sub_sort, \n",
    "#                         year=factor(year),\n",
    "#                         pdismiss=factor(pdismiss, levels=c(0,1)),\n",
    "#                         pnhprev=factor(pnhprev, levels=c(0,1)), bmi_msg=factor(bmi_msg, levels=c(0,1)),\n",
    "#                         ashd1=factor(ashd1, levels=c(0,1)), othcardiac1=factor(othcardiac1, levels=c(0,1)),\n",
    "#                         carfail=factor(carfail, levels=c(0,1)), noambul=factor(noambul, levels=c(0,1)),\n",
    "#                         pulmon=factor(pulmon, levels=c(0,1)), notrans=factor(notrans, levels=c(0,1)),\n",
    "#                         cancer=factor(cancer, levels=c(0,1)), diabetes=factor(diabetes, levels=c(0,1)),\n",
    "#                         pvasc=factor(pvasc, levels=c(0,1)), cva=factor(cva, levels=c(0,1)), \n",
    "#                         smoke=factor(smoke, levels=c(0,1)), alcoh=factor(alcoh, levels=c(0,1)),drug=factor(drug, levels=c(0,1)), inci_one=factor(inci_one, levels=c(0,1)),\n",
    "#                         inci_miss=factor(inci_miss, levels=c(0,1)))\n",
    "\n",
    "\n",
    "# #COX PROPORTIONAL HAZARDS MODEL 1\n",
    "# if(test==1){\n",
    "#   coxph_control <- coxph.control(eps = 1e-8, iter.max = imax)\n",
    "# } else\n",
    "# {\n",
    "#   coxph_control <- coxph.control(eps = 1e-8)\n",
    "# }\n",
    "\n",
    "data_sub_sort['year'] = pd.Categorical(data_sub_sort['year'], ordered=False)\n",
    "data_sub_sort['pdismiss'] = pd.Categorical(data_sub_sort['pdismiss'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['pnhprev'] = pd.Categorical(data_sub_sort['pnhprev'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['bmi_msg'] = pd.Categorical(data_sub_sort['bmi_msg'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['ashd1'] = pd.Categorical(data_sub_sort['ashd1'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['othcardiac1'] = pd.Categorical(data_sub_sort['othcardiac1'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['carfail'] = pd.Categorical(data_sub_sort['carfail'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['noambul'] = pd.Categorical(data_sub_sort['noambul'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['pulmon'] = pd.Categorical(data_sub_sort['pulmon'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['notrans'] = pd.Categorical(data_sub_sort['notrans'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['cancer'] = pd.Categorical(data_sub_sort['cancer'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['diabetes'] = pd.Categorical(data_sub_sort['diabetes'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['pvasc'] = pd.Categorical(data_sub_sort['pvasc'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['cva'] = pd.Categorical(data_sub_sort['cva'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['smoke'] = pd.Categorical(data_sub_sort['smoke'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['alcoh'] = pd.Categorical(data_sub_sort['alcoh'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['drug'] = pd.Categorical(data_sub_sort['drug'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['inci_one'] = pd.Categorical(data_sub_sort['inci_one'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['inci_miss'] = pd.Categorical(data_sub_sort['inci_miss'], categories=[0, 1], ordered=False)\n",
    "data_sub_sort['smoke'] = pd.Categorical(data_sub_sort['smoke'], categories=[0, 1], ordered=False)\n",
    "\n",
    "data_sub_sort['provfs'] = pd.Categorical(data_sub_sort['provfs'], ordered=False)\n",
    "\n",
    "# coxph_control <- coxph.control(eps = 1e-8)\n",
    "# data_sub_sort.transform(lambda x: x + 1)\n",
    "\n",
    "data_model = data_sub_sort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub_sort['provfs'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Read data \n",
    "# Artificail weights logic\n",
    "#packages survival, RCurl, reshape, dplyr, plyr, devtools, sparklyr, sparkR\n",
    "#\n",
    "#h2o.init(max_mem_size = \"16g\",nthreads = -1)\n",
    "###############################################################################################################\n",
    "# data_modelt_Full_Sample<-data_model\n",
    "\n",
    "# # Artificial weights logic\n",
    "# data_modelt_Full_Sample <- data_modelt_Full_Sample[rep(row.names(data_modelt_Full_Sample), data_modelt_Full_Sample$wt_trans), ] \n",
    "# data_modelt_Full_Sample$provfs<-as.factor(data_modelt_Full_Sample$provfs)\n",
    "\n",
    "# data_modelt_Full_Sample_hex<-as.h2o(data_modelt_Full_Sample)\n",
    "# #data_modelt_Full_Sample_hex$provfs<-as.factor(data_modelt_Full_Sample_hex$provfs)\n",
    "# data_modelt_Full_Sample_hex$agecat6<-as.factor(data_modelt_Full_Sample_hex$agecat6)\n",
    "# data_modelt_Full_Sample_hex$pyf_period_esrd<-as.factor(data_modelt_Full_Sample_hex$pyf_period_esrd)\n",
    "# data_modelt_Full_Sample_hex$year<-as.factor(data_modelt_Full_Sample_hex$year)\n",
    "# #data_modelt_Full_Sample_hex$wt_trans<- as.numeric(data_modelt_Full_Sample_hex$wt_trans)\n",
    "#######################################################################################################################################################\n",
    "# Run Stage-1 Cox Model\n",
    "#######################################################################################################################################################\n",
    "# predictorsSt <- c(\"agecat6\", \"pdiab\", \"pdismiss\",\"notrans\",\"cancer\",\"diabetes\",\"pvasc\",\"year\",\n",
    "#                   \"pnhprev\", \"logbmi\", \"bmi_msg\",\"cva\",\"smoke\",\"alcoh\",\"drug\",\"inci_one\",\n",
    "#                   \"ashd1\", \"pulmon\",\"inci_miss\",\"year\",\"othcardiac1\",\n",
    "#                   \"carfail\", \"noambul\", \"pulmon\")\n",
    "\n",
    "# h2o_modelt_D1_p <- h2o.coxph(\n",
    "#   x = predictorsSt,\n",
    "#   event_column = \"t_trans0\",\n",
    "#   start_column = \"t_start\",\n",
    "#   stop_column = \"t_stop\",\n",
    "#   offset_column = \"ot_trans\",\n",
    "#   ties = c(\"breslow\"),\n",
    "#   stratify_by = (\"provfs\"),\n",
    "#   interaction_pairs=list(\n",
    "#     c(\"agecat6\",\"pdiab\"),\n",
    "#     c(\"pdiab\", \"pyf_period_esrd\")\n",
    "#   ),\n",
    "#   training_frame = data_modelt_Full_Sample_hex)\n",
    "\n",
    "# coefficients_Stage_1<-h2o_modelt_D1_p@model$coefficients_table$coefficients\n",
    "\n",
    "\n",
    "#############################################\n",
    "import h2o\n",
    "from h2o.estimators.coxph import H2OCoxProportionalHazardsEstimator\n",
    "h2o.init()\n",
    "\n",
    "data_modelt_Full_Sample=data_model\n",
    "data_modelt_Full_Sample.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data_modelt_Full_Sample_hex = h2o.H2OFrame(data_modelt_Full_Sample)\n",
    "data_modelt_Full_Sample_hex[data_modelt_Full_Sample_hex[\"provfs\"].isna(), \"provfs\"] = 0\n",
    "# data_modelt_Full_Sample_hex[\"provfs\"] = data_modelt_Full_Sample_hex[\"provfs\"].ascharacter()\n",
    "# data_modelt_Full_Sample_hex[\"provfs\"] = data_modelt_Full_Sample_hex[\"provfs\"].asfactor()\n",
    "predictorsSt = list([\"agecat6\", \"pdiab\", \"pdismiss\",\"notrans\",\"cancer\",\n",
    "                \"diabetes\",\"pvasc\",\"year\", \"pnhprev\", \"logbmi\", \n",
    "                \"bmi_msg\",\"cva\",\"smoke\",\"alcoh\",\"drug\",\n",
    "                \"inci_one\", \"ashd1\", \"pulmon\",\"inci_miss\",\"year\",\n",
    "                \"othcardiac1\", \"carfail\", \"noambul\", \"pulmon\"])\n",
    "\n",
    "interaction_pairs = [   (\"agecat6\",\"pdiab\"), \n",
    "                        (\"pdiab\", \"pyf_period_esrd\")]\n",
    "\n",
    "strr_h2o_moodel = H2OCoxProportionalHazardsEstimator(\n",
    "    start_column=\"t_start\",\n",
    "    stop_column=\"t_stop\",\n",
    "    offset_column=\"ot_trans\",\n",
    "    ties=\"breslow\",\n",
    "#     stratify_by=[\"provfs\"],\n",
    "#     interaction_pairs=interaction_pairs,\n",
    "    )\n",
    "\n",
    "strr_h2o_moodel.train(x=predictorsSt,\n",
    "                y=\"t_trans0\",\n",
    "                training_frame=data_modelt_Full_Sample_hex)\n",
    "                        \n",
    "# coefficients_Stage_1<-strr_h2o_moodel.model.coefficients_table.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing to csv\n",
    "pd.DataFrame(data_modelt_Full_Sample_hex[\"provfs\"]).to_csv('provfs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_modelt_Full_Sample_hex['provfs'].types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strr_h2o_moodel.coefficients_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_modelt_Full_Sample_hex['t_trans0'].types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_modelt_Full_Sample_hex[\"t_trans0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_modelt_Full_Sample_hex.col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_modelt_Full_Sample_hex.types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lifeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from lifelines import CoxPHFitter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lifelines.datasets import load_rossi\n",
    "rossi = load_rossi()\n",
    "cph = CoxPHFitter()\n",
    "\n",
    "cph.fit(rossi, 'week', 'arrest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rossi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph.print_summary(model=\"untransformed variables\", decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph.check_assumptions(rossi, p_value_threshold=0.05, show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines.statistics import proportional_hazard_test\n",
    "\n",
    "results = proportional_hazard_test(cph, rossi, time_transform='rank')\n",
    "results.print_summary(decimals=3, model=\"untransformed variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratification\n",
    "cph.fit(rossi, 'week', 'arrest', strata=['wexp'])\n",
    "cph.print_summary(model=\"wexp in strata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph.check_assumptions(rossi, show_plots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H2O Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "f = os.popen('sudo su; export PATH=$PATH:/opt/h2o; source ~/.bashrc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Airline example\n",
    "# https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/interaction_pairs.html\n",
    "import h2o\n",
    "h2o.init()\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "\n",
    "# import the airlines dataset\n",
    "df_air = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\")\n",
    "\n",
    "# specify the columns to include\n",
    "XY = [df_air.names[i-1] for i in [1,2,3,4,6,8,9,13,17,18,19,31]]\n",
    "\n",
    "# specify the predictor column indices to interact\n",
    "interactions = [XY[i-1] for i in [5,7,9]]\n",
    "\n",
    "# train the model and build the coefficients table\n",
    "m = H2OGeneralizedLinearEstimator(lambda_search=True,\n",
    "                                  family=\"binomial\",\n",
    "                                  interactions=interactions)\n",
    "m.train(x=XY[:len(XY)], y=XY[-1],training_frame=df)\n",
    "coef_m = m._model_json['output']['coefficients_table']\n",
    "\n",
    "# define specific interaction pairs\n",
    "interaction_pairs = [(\"CRSDepTime\", \"UniqueCarrier\"),\n",
    "                     (\"CRSDepTime\", \"Origin\"),\n",
    "                     (\"UniqueCarrier\", \"Origin\")]\n",
    "\n",
    "# train the model with the interaction pairs\n",
    "mexp = H2OGeneralizedLinearEstimator(lambda_search=True,\n",
    "                                     family=\"binomial\",\n",
    "                                     interaction_pairs=interaction_pairs)\n",
    "mexp.train(x=XY[:len(XY)], y=XY[-1],training_frame=df)\n",
    "coef_mexp = mexp._model_json['output']['coefficients_table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/coxph.html\n",
    "import h2o\n",
    "from h2o.estimators.coxph import H2OCoxProportionalHazardsEstimator\n",
    "h2o.init()\n",
    "\n",
    "# Import the heart dataset into H2O:\n",
    "heart = h2o.import_file(\"http://s3.amazonaws.com/h2o-public-test-data/smalldata/coxph_test/heart.csv\")\n",
    "\n",
    "# Split the dataset into a train and test set:\n",
    "train, test = heart.split_frame(ratios = [.8], seed = 1234)\n",
    "\n",
    "# Build and train the model:\n",
    "heart_coxph = H2OCoxProportionalHazardsEstimator(start_column=\"start\",\n",
    "                                                 stop_column=\"stop\",\n",
    "                                                 ties=\"breslow\")\n",
    "heart_coxph.train(x=\"age\",\n",
    "            y=\"event\",\n",
    "            training_frame=train)\n",
    "\n",
    "# Generate predictions on a test set (if necessary):\n",
    "pred = heart_coxph.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=heart[\"age\"].ascharacter()\n",
    "b=a.asfactor()\n",
    "b.types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/algo-params/stratify_by.html\n",
    "import h2o\n",
    "from h2o.estimators import H2OCoxProportionalHazardsEstimator\n",
    "h2o.init()\n",
    "\n",
    "# import the heart dataset:\n",
    "heart = h2o.import_file(\"http://s3.amazonaws.com/h2o-public-test-data/smalldata/coxph_test/heart.csv\")\n",
    "\n",
    "# set the predictor and response column:\n",
    "x = [\"age\", \"year\"]\n",
    "y = \"event\"\n",
    "\n",
    "# convert the age column to a factor:\n",
    "heart[\"age\"] = heart[\"age\"].ascharacter()\n",
    "heart[\"age\"] = heart[\"age\"].asfactor()\n",
    "\n",
    "# build and train your model:\n",
    "heart_coxph = H2OCoxProportionalHazardsEstimator(start_column=\"start\",\n",
    "                                                 stop_column=\"stop\",\n",
    "                                                 ties=\"breslow\",\n",
    "                                                 stratify_by=[\"age\"])\n",
    "heart_coxph.train(x=x, y=y, training_frame=heart)\n",
    "\n",
    "# view the model details:\n",
    "heart_coxph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#############################################################\n",
    "# Creation of Dummy variables to match Therneau model\n",
    "#########################################################\n",
    "data_modelt<-data_model\n",
    "#large data set data_modelt\n",
    "\n",
    "data_modelt$agecat62 <- ifelse(data_modelt$agecat6==2, 1,0) \n",
    "data_modelt$agecat63 <- ifelse(data_modelt$agecat6==3, 1,0)\n",
    "data_modelt$agecat64 <- ifelse(data_modelt$agecat6==4, 1,0) \n",
    "data_modelt$agecat66 <- ifelse(data_modelt$agecat6==6, 1,0) \n",
    "\n",
    "\n",
    "data_modelt$agecat62p <- (ifelse(data_modelt$agecat6==2, 1,0))*data_modelt$pdiab\n",
    "data_modelt$agecat63p <- (ifelse(data_modelt$agecat6==3, 1,0))*data_modelt$pdiab\n",
    "data_modelt$agecat64p <- (ifelse(data_modelt$agecat6==4, 1,0))*data_modelt$pdiab\n",
    "data_modelt$agecat66p <- (ifelse(data_modelt$agecat6==6, 1,0))*data_modelt$pdiab\n",
    "\n",
    "\n",
    "data_modelt$pyf_period_esrd2p <- (ifelse(data_modelt$pyf_period_esrd==2, 1,0))*data_modelt$pdiab \n",
    "data_modelt$pyf_period_esrd3p <- (ifelse(data_modelt$pyf_period_esrd==3, 1,0))*data_modelt$pdiab \n",
    "data_modelt$pyf_period_esrd4p <- (ifelse(data_modelt$pyf_period_esrd==4, 1,0))*data_modelt$pdiab \n",
    "data_modelt$pyf_period_esrd5p <- (ifelse(data_modelt$pyf_period_esrd==5, 1,0))*data_modelt$pdiab \n",
    "data_modelt$pyf_period_esrd6p <- (ifelse(data_modelt$pyf_period_esrd==6, 1,0))*data_modelt$pdiab \n",
    "\n",
    "data_modelt$year2016 <- ifelse(data_modelt$year==\"2016\", 1,0) \n",
    "data_modelt$year2017 <- ifelse(data_modelt$year==\"2017\", 1,0)\n",
    "data_modelt$year2018 <- ifelse(data_modelt$year==\"2018\", 1,0) \n",
    "\n",
    "\n",
    "data_modelt$inci_miss1<-as.numeric(as.character(data_modelt$inci_miss))\n",
    "data_modelt$pdismiss1<-as.numeric(as.character(data_modelt$pdismiss))\n",
    "data_modelt$bmi_msg1<-as.numeric(as.character(data_modelt$bmi_msg))\n",
    "data_modelt$ashd11<-as.numeric(as.character(data_modelt$ashd1))\n",
    "\n",
    "data_modelt$othcardiac11<-as.numeric(as.character(data_modelt$othcardiac1))\n",
    "data_modelt$carfail1<-as.numeric(as.character(data_modelt$carfail))\n",
    "data_modelt$noambul1<-as.numeric(as.character(data_modelt$noambul))\n",
    "data_modelt$pulmon1<-as.numeric(as.character(data_modelt$pulmon))\n",
    "\n",
    "data_modelt$notrans1<-as.numeric(as.character(data_modelt$notrans))\n",
    "data_modelt$cancer1<-as.numeric(as.character(data_modelt$cancer))\n",
    "data_modelt$diabetes1<-as.numeric(as.character(data_modelt$diabetes))\n",
    "data_modelt$pvasc1<-as.numeric(as.character(data_modelt$pvasc))\n",
    "\n",
    "data_modelt$cva1<-as.numeric(as.character(data_modelt$cva))\n",
    "data_modelt$smoke1<-as.numeric(as.character(data_modelt$smoke))\n",
    "data_modelt$alcoh1<-as.numeric(as.character(data_modelt$alcoh))\n",
    "data_modelt$drug1<-as.numeric(as.character(data_modelt$drug))\n",
    "\n",
    "data_modelt$inci_one1<-as.numeric(as.character(data_modelt$inci_one))\n",
    "data_modelt$pnhprev1<-as.numeric(as.character(data_modelt$pnhprev))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "# Matrix Reformulation of data_modelt using dummy variables  -  model1\n",
    "####################################################################################\n",
    "\n",
    "xf50<-as.matrix(cbind(data_modelt[, \"agecat62\"], data_modelt[, \"agecat63\"],data_modelt[, \"agecat64\"],data_modelt[, \"agecat66\"],\n",
    "                      data_modelt[, \"year2016\"], data_modelt[, \"year2017\"],data_modelt[, \"year2018\"], data_modelt[, \"bmi_msg1\"],\n",
    "                      data_modelt[, \"pdismiss1\"],data_modelt[, \"pnhprev1\"],\n",
    "                      data_modelt[, \"ashd11\"], data_modelt[, \"othcardiac11\"],data_modelt[, \"carfail1\"],data_modelt[, \"noambul1\"], \n",
    "                      data_modelt[, \"pulmon1\"],data_modelt[, \"notrans1\"],data_modelt[, \"cancer1\"],data_modelt[, \"diabetes1\"],\n",
    "                      data_modelt[, \"pvasc1\"],data_modelt[, \"cva1\"], data_modelt[, \"smoke1\"],data_modelt[, \"alcoh1\"],\n",
    "                      data_modelt[, \"drug1\"], data_modelt[, \"inci_one1\"],data_modelt[, \"inci_miss1\"],\n",
    "                      data_modelt[, \"agecat62p\"],data_modelt[, \"agecat63p\"], data_modelt[, \"agecat64p\"],data_modelt[, \"agecat66p\"],\n",
    "                      data_modelt[, \"pyf_period_esrd2p\"],data_modelt[, \"pyf_period_esrd3p\"],data_modelt[, \"pyf_period_esrd4p\"],data_modelt[, \"pyf_period_esrd5p\"], data_modelt[, \"pyf_period_esrd6p\"],\n",
    "                      data_modelt[, \"pdiab\"],data_modelt[, \"logbmi\"]\n",
    "))\n",
    "############################################################\n",
    "# H2O Model coefficients rearranged to match survival model\n",
    "############################################################\n",
    "\n",
    "#Coef <- read_csv(\"Z:/Divya/h2o/Coef.csv\")\n",
    "\n",
    "#H2OCox<-Coef\n",
    "\n",
    "#names(H2OCox)[2]<-\"coef\"\n",
    "\n",
    "#names(H2OCox)[1]<-\"var\"\n",
    "\n",
    "#H2OCoxT<-H2OCox[c(1,2,3,4,17:21,5,6,7,22:36,12:16,8:11),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# Linear Predictor Calculations - from Terry Therneau equation - Model Means taken from H2O object\n",
    "###############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "lpH2O<- c(xf50%*%coefficients_Stage_1) + data_modelt$ot_trans - sum(coefficients_Stage_1*colMeans(xf50))\n",
    "\n",
    "\n",
    "###########################################################\n",
    "# H2O Model Comparison using A. Weights Breslow H2O Cox PH Run - Best Model results\n",
    "################################################################\n",
    "\n",
    "modelH2OAWB<- coxph(Surv(t_start, t_stop, t_trans0)~1+ offset(lpH2O),\n",
    "                    data=data_modelt, weights=wt_trans, ties=\"breslow\", control=coxph_control)\n",
    "\n",
    "\n",
    "data_modeltH2OAWB<-data_modelt\n",
    "\n",
    "data_modeltH2OAWB$resid <- residuals(modelH2OAWB,type=\"martingale\")\n",
    "\n",
    "data_modeltH2OAWB$expecttr <- data_modeltH2OAWB$wt_trans*(data_modeltH2OAWB$t_trans0-data_modeltH2OAWB$resid)\n",
    "\n",
    "#output expected number of transfusions along with id variables\n",
    "expect_outH2OAWB<- data_modeltH2OAWB[ ,c(\"provfs\",\"ptnt_id\",\"year\",\"strr_pyf_start\",\"expecttr\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "########################################################################################\n",
    "# SECTION 14: SUMMARIZE TO FACILITY LEVEL AND OUTPUT STrR FOR EACH FACILITY COX H2O Model        #\n",
    "########################################################################################\n",
    "\n",
    "sub.dataH2OAWB <- data_modeltH2OAWB[ ,c(\"provfs\",\"t_trans\",\"expecttr\")]\n",
    "\n",
    "agg.dataH2OAWB <- aggregate(sub.dataH2OAWB[ ,-1], by=list(sub.dataH2OAWB$provfs), \"sum\")\n",
    "\n",
    "sum.dataH2OAWB <- agg.dataH2OAWB[ ,c(\"Group.1\",\"t_trans\",\"expecttr\")]\n",
    "\n",
    "for (i in 1:nrow(sum.dataH2OAWB)){\n",
    "  if (sum.dataH2OAWB$expecttr[i]>0) {\n",
    "    sum.dataH2OAWB$strr[i] <- sum.dataH2OAWB$t_trans[i]/sum.dataH2OAWB$expecttr[i]\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "colnames(sum.dataH2OAWB)[1] <- \"provfs\"\n",
    "#print(sum.dataH2OAWB)\n",
    "\n",
    "#boxplot(sum.dataH2OAWBCompare$strr_H2O_AWB, sum.dataH2OAWBCompare$strr_Legacy, names=c(\"H2O AWB Cox\",\"Legacy Cox\"),main=\"Comparison of STrR Ratios for H2O Cox vs Legacy Cox Model\",ylim=c(0,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparkling Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# from pyspark import SparkConf, SparkContext\n",
    "# import h2o\n",
    "from pysparkling import *\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"H2O_Test\")\\\n",
    "    .getOrCreate()\n",
    "conf = H2OConf().setExternalClusterMode().useManualClusterStart().setCloudName(\"test\")\n",
    "hc = H2OContext.getOrCreate(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Plant Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/jakubhava/automl_blog_post\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pysparkling import *\n",
    "\n",
    "# spark = SparkSession\\\n",
    "#     .builder\\\n",
    "#     .appName(\"GeneralizedLinearRegressionExample\")\\\n",
    "#     .getOrCreate()\n",
    "spark = SparkSession.builder.appName(\"PowerPlantExample\").getOrCreate()\n",
    "conf = H2OConf().setExternalClusterMode().useManualClusterStart().setCloudName(\"test\")\n",
    "hc = H2OContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerplant_df = spark.read.option(\"inferSchema\", \"true\").csv(\"powerplant_output.csv\", header=True)\n",
    "splits = powerplant_df.randomSplit([0.8, 0.2], 1)\n",
    "train = splits[0]\n",
    "for_predictions = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysparkling.ml import H2OAutoML\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import SQLTransformer\n",
    "temperatureTransformer = SQLTransformer(statement=\"SELECT * FROM __THIS__ WHERE TemperatureCelcius > 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatureTransformer.transform(powerplant_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automlEstimator = H2OAutoML(maxRuntimeSecs=60, predictionCol=\"HourlyEnergyOutputMW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[temperatureTransformer.transform(powerplant_df), automlEstimator])\n",
    "# pipeline = Pipeline(stages=[automlEstimator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerplant_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_predictions.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = automlEstimator.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import AFTSurvivalRegression \n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "# $example on$\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "# $example off$\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"GeneralizedLinearRegressionExample\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # $example on$\n",
    "    # Load training data\n",
    "    dataset = spark.read.format(\"libsvm\")\\\n",
    "        .load(\"s3://eqrs-ngmc-datascience/Datascience/x.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# $example on$\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "# $example off$\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"GeneralizedLinearRegressionExample\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # $example on$\n",
    "    # Load training data\n",
    "    dataset = spark.read.format(\"libsvm\")\\\n",
    "        .load(\"sample_linear_regression_data.txt\")\n",
    "\n",
    "    family = (\"gaussian\",\"Gamma\")\n",
    "    link=(\"identity\", \"Log\", \"Inverse\")\n",
    "    maxIter=(10,100,1000)\n",
    "    regParam=(0.1, 0.3, 0.5)\n",
    "    params = [[i, j, k, l] for i in family  \n",
    "                     for j in link \n",
    "                     for k in maxIter\n",
    "                     for l in regParam] \n",
    "    for p in params:\n",
    "        glr = GeneralizedLinearRegression(family=p[0], link=p[1], maxIter=p[2], regParam=p[3])\n",
    "\n",
    "        # Fit the model\n",
    "        model = glr.fit(dataset)\n",
    "\n",
    "        # Print the coefficients and intercept for generalized linear regression model\n",
    "        print(\"Coefficients: \" + str(model.coefficients))\n",
    "        print(\"Intercept: \" + str(model.intercept))\n",
    "\n",
    "        # Summarize the model over the training set and print out some metrics\n",
    "        print(p);print();print()\n",
    "        summary = model.summary\n",
    "        print(\"Coefficient Standard Errors: \" + str(summary.coefficientStandardErrors))\n",
    "        print(\"T Values: \" + str(summary.tValues))\n",
    "        print(\"P Values: \" + str(summary.pValues))\n",
    "        print(\"Dispersion: \" + str(summary.dispersion))\n",
    "        print(\"Null Deviance: \" + str(summary.nullDeviance))\n",
    "        print(\"Residual Degree Of Freedom Null: \" + str(summary.residualDegreeOfFreedomNull))\n",
    "        print(\"Deviance: \" + str(summary.deviance))\n",
    "        print(\"Residual Degree Of Freedom: \" + str(summary.residualDegreeOfFreedom))\n",
    "        print(\"AIC: \" + str(summary.aic))\n",
    "        print(\"Deviance Residuals: \")\n",
    "        summary.residuals().show()\n",
    "        # $example off$\n",
    "\n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
